# Helionyx Production (Live) Environment Configuration
#
# This is a complete example for the PRODUCTION/LIVE environment.
# 
# TO USE:
#   1. Copy this file: cp .env.live.example .env.live
#   2. Replace <placeholder> values with your actual credentials
#   3. Run with: ENV=live make run (or specify ENV=live in your command)
#
# ENVIRONMENT: Production/Live (minimal logging, production paths, higher cost limits)
# PORT: 8002 (standard live port)
# SERVICE: helionyx.service (canonical production service name)

# =============================================================================
# Environment
# =============================================================================
# Note: ENV is set via CLI (ENV=live), not in this file

# =============================================================================
# API Server
# =============================================================================
# Bind to all interfaces (or restrict to 127.0.0.1 if behind proxy)
API_HOST=0.0.0.0

# Live environment uses port 8002 (distinct from dev=8000, staging=8001)
API_PORT=8002

# =============================================================================
# Storage (Production Paths)
# =============================================================================

# Event store - production absolute path
EVENT_STORE_PATH=/var/lib/helionyx/live/events

# Projections database - production absolute path
PROJECTIONS_DB_PATH=/var/lib/helionyx/live/projections/helionyx.db

# Backups (recommended)
BACKUP_ROOT=/var/lib/helionyx/backups

# =============================================================================
# OpenAI LLM
# =============================================================================

# Required: Your OpenAI API key (production key, monitor usage carefully)
OPENAI_API_KEY=<your_openai_api_key_here>

# Consider using more capable model for production if needed
# Options: gpt-4o-mini (cost-efficient), gpt-4o (more capable)
OPENAI_MODEL=gpt-4o

# Standard parameters (tune based on production needs)
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.7

# Rate limiting (adjust based on your OpenAI tier)
OPENAI_RATE_LIMIT_RPM=10
OPENAI_RATE_LIMIT_TPM=150000

# Error handling
LLM_MAX_RETRIES=3
LLM_RETRY_BASE_DELAY=1.0

# Cost control - HIGHER limits for production (adjust to your budget)
# Warning triggers notification, limit halts LLM calls
LLM_DAILY_COST_WARNING_USD=5.0
LLM_DAILY_COST_LIMIT_USD=50.0

# =============================================================================
# Telegram Bot (Production Bot)
# =============================================================================
# Required: Create a SEPARATE bot for production via @BotFather
# Bot name suggestion: helionyx_bot (simple, canonical name)
#
# Setup:
#   1. Open Telegram, chat with @BotFather
#   2. Send: /newbot
#   3. Name: helionyx_bot  (or similar)
#   4. Copy the token below
#
# CRITICAL: Use a different bot than dev/staging to ensure production isolation
TELEGRAM_BOT_TOKEN=<your_live_bot_token_from_botfather>

# Your Telegram user chat ID (same user as dev/staging)
TELEGRAM_CHAT_ID=<your_telegram_user_id>

# Notification settings - ENABLED for production operations
NOTIFICATIONS_ENABLED=true

# Notification timing (adjust to your preference)
DAILY_SUMMARY_HOUR=20          # 8 PM daily summary
REMINDER_WINDOW_START=8        # Reminders only between 8 AM - 9 PM
REMINDER_WINDOW_END=21
REMINDER_ADVANCE_HOURS=24      # Remind 24h before due date

# =============================================================================
# Logging
# =============================================================================
# Minimal logging for production (WARNING captures important events only)
# Consider INFO if you need more visibility during initial production rollout
LOG_LEVEL=WARNING
